{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMs4oNcJshcS"
   },
   "source": [
    "# MovieLens Popularity Model\n",
    "\n",
    "This notebook creates and evaluates a baseline recommendation model, based on popularity.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Data prep - download the raw dataset, and prepare it for training and evaluation.\n",
    "1. Model authoring - build the popularity based model.\n",
    "1. Model evaluation - benchmark the popularity model to achieve a baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET_FOLDER = os.getcwd()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFZ6Np1Xs2_L"
   },
   "source": [
    "## Step 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLIQ1A2osbGO",
    "outputId": "98f2ec96-bafa-44f2-f5f3-b44d885d9763"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import tempfile\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "def load_movielens_dataset(dataset_name = 'ml-latest', workspace_path = DATASET_FOLDER + '/data/movielens'):\n",
    "    \"\"\"\n",
    "    Downloads, extracts, and loads MovieLens dataset \n",
    "\n",
    "    Args:\n",
    "    dataset_name (string): dataset name to load, defaults to 'ml_latest'. Options listed here: https://grouplens.org/datasets/movielens/\n",
    "    workspace_path (string): workspace path to use for downloading and extracting the archive, defaults to ~/data/movielens\n",
    "    \"\"\"\n",
    "\n",
    "    archive_url = f'http://files.grouplens.org/datasets/movielens/{dataset_name}.zip'\n",
    "\n",
    "    print(f'Downloading archive from: {archive_url}, this may take a few minutes...')\n",
    "\n",
    "    with urllib.request.urlopen(archive_url) as response:\n",
    "        with tempfile.NamedTemporaryFile(delete=True) as tmp_file:\n",
    "            shutil.copyfileobj(response, tmp_file)\n",
    "            with zipfile.ZipFile(tmp_file) as archive:\n",
    "                archive.extractall(workspace_path)\n",
    "\n",
    "    print(f'Archive files available at workspace: {workspace_path}')\n",
    "\n",
    "    ratings = pd.read_csv(f'{workspace_path}/{dataset_name}/ratings.csv')\n",
    "    movies = pd.read_csv(f'{workspace_path}/{dataset_name}/movies.csv')\n",
    "\n",
    "    print(f'Loaded {ratings.shape[0]:,} ratings and {movies.shape[0]:,} movies.')\n",
    "\n",
    "    return ratings, movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's load some movie ratings!\n",
    "# ratings, movies = load_movielens_dataset(dataset_name='ml-latest')\n",
    "\n",
    "workspace_path = 'data/movielens'\n",
    "dataset_name = 'ml-latest'\n",
    "\n",
    "ratings = pd.read_csv(f\"{workspace_path}/{dataset_name}/ratings.csv\")\n",
    "movies = pd.read_csv(f\"{workspace_path}/{dataset_name}/movies.csv\")\n",
    "user_count = ratings[\"userId\"].nunique()\n",
    "movie_count = movies[\"movieId\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5zIrYOMtkdT",
    "outputId": "971b9194-c93e-487a-87d3-fdbd558db842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneak peek into the ratings DataFrame:\n",
      "\n",
      "    userId  movieId  rating   timestamp\n",
      "0       1      307     3.5  1256677221\n",
      "1       1      481     3.5  1256677456\n",
      "2       1     1091     1.5  1256677471\n",
      "3       1     1257     4.5  1256677460\n",
      "4       1     1449     4.5  1256677264 \n",
      "\n",
      "Number of ratings:  27753444\n",
      "Sneak peek into the movies DataFrame:\n",
      "\n",
      "    movieId                               title   \n",
      "0        1                    Toy Story (1995)  \\\n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy   \n",
      "\n",
      "Number of movies:  58098  - notice this is higher than the number of rated movies!\n"
     ]
    }
   ],
   "source": [
    "# Let's peek into the loaded DataFrames\n",
    "print('Sneak peek into the ratings DataFrame:\\n\\n', ratings.head(), '\\n')\n",
    "print('Number of ratings: ', ratings.shape[0])\n",
    "print('Sneak peek into the movies DataFrame:\\n\\n', movies.head(), '\\n')\n",
    "print('Number of movies: ', movies['movieId'].nunique(), ' - notice this is higher than the number of rated movies!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piXXL7ti-qH0"
   },
   "source": [
    "Next we divide our dataset into train and test, so we can later evaluate the popularity model on the test dataset, and achieve a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGV1G1bw-zO1",
    "outputId": "26a307a5-e1df-49ca-aaed-958eddc050c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset sample size: 22,202,755 positive samples (80%)\n",
      "Test dataset sample size: 5,550,689 positive samples (20%)\n",
      "Total dataset sample size: 27,753,444 positive samples (100%)\n"
     ]
    }
   ],
   "source": [
    "# Define our input and labels data X,Y\n",
    "dataset = ratings[['userId','movieId','rating']]\n",
    "\n",
    "# We don't need to train this model, however we will choose a random subset for testing, to be aligned with trained models evaluated later on\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 42\n",
    "test_size = 0.2\n",
    "\n",
    "dataset_train, dataset_valid = train_test_split(dataset, test_size = test_size, random_state = random_state)\n",
    "\n",
    "print(f'Training dataset sample size: {len(dataset_train):,} positive samples ({len(dataset_train)/len(dataset)*100:.0f}%)')\n",
    "print(f'Test dataset sample size: {len(dataset_valid):,} positive samples ({len(dataset_valid)/len(dataset)*100:.0f}%)')\n",
    "print(f'Total dataset sample size: {len(dataset):,} positive samples (100%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egFcOMPTt7uv"
   },
   "source": [
    "## Step 2: Preparing the popularity model\n",
    "Our popularity model will predict a user's rating for a given movie by averaging all other ratings provided for this movie.\n",
    "\n",
    "In more concrete terms, our algorithm will:  \n",
    "1. Compute average rating per movie and store the values\n",
    "1. For a given prediction request, return the average rating for the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "IcA0erFX6TfN",
    "outputId": "183df349-0bec-4d86-c4e7-54e01c73965b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.888161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.246433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.172547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.886079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.077933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193872</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193874</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193876</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193878</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193886</th>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51559 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rating\n",
       "movieId          \n",
       "1        3.888161\n",
       "2        3.246433\n",
       "3        3.172547\n",
       "4        2.886079\n",
       "5        3.077933\n",
       "...           ...\n",
       "193872   4.000000\n",
       "193874   5.000000\n",
       "193876   3.000000\n",
       "193878   2.000000\n",
       "193886   3.250000\n",
       "\n",
       "[51559 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the average rating per movie on the training set, and take a quick look\n",
    "train_average_rating = pd.DataFrame(dataset_train.groupby([\"movieId\"]).mean()['rating'])\n",
    "train_average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1weU1hlvBIcu",
    "outputId": "a27ada18-6a99-4507-afe7-4f2d1a7b7d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity model initializing...\n",
      "Popularity model instantiated, includes 51,559 mappings.\n"
     ]
    }
   ],
   "source": [
    "# create popularity model, which will be a simple dictionary mapping movieId to predicted rating\n",
    "\n",
    "class PopModel:\n",
    "    \"Encapsulates popularity based movie rating prediction\"\n",
    "\n",
    "    def __init__(self, dataset_train):\n",
    "        print('Popularity model initializing...')\n",
    "        self.DEFAULT_RATING = 3\n",
    "        self._popModel = {}\n",
    "        train_average_rating = pd.DataFrame(dataset_train.groupby([\"movieId\"]).mean()['rating'])\n",
    "        for movieId, row in train_average_rating.iterrows():\n",
    "            self._popModel[movieId] = row.rating\n",
    "        print(f'Popularity model instantiated, includes {len(self._popModel):,} mappings.')\n",
    "\n",
    "    def predictRating(self, movieId):\n",
    "        if movieId in self._popModel:\n",
    "            return self._popModel[movieId]\n",
    "        else: \n",
    "            return self.DEFAULT_RATING\n",
    "\n",
    "popModel = PopModel(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUVJ3g_MYmnG",
    "outputId": "28a132f4-aa69-465e-a3bb-abc889c9eed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry run prediction for user-id:209311 and movie-id:111362 is: 3.7518554150632215, actual rating is: 5.0\n"
     ]
    }
   ],
   "source": [
    "from random  import randrange\n",
    "\n",
    "# Let's try a random prediction\n",
    "ratings_row = randrange(0, ratings.shape[0] - 1)\n",
    "test_user = int(ratings.iloc[ratings_row].userId)\n",
    "test_movie = int(ratings.iloc[ratings_row].movieId)\n",
    "actual_rating = ratings.iloc[ratings_row].rating\n",
    "\n",
    "predicted_rating = popModel.predictRating(test_movie)\n",
    "print(f\"Dry run prediction for user-id:{test_user} and movie-id:{test_movie} is: {predicted_rating}, actual rating is: {actual_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIqg5-Xt9H6x"
   },
   "source": [
    "## Step 3: Evaluating the popularity model\n",
    "Next we'll run an evaluation of the model, which will serve us as a baseline later on when we evaluate and explore personalized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "F08eGOJVaiqq"
   },
   "outputs": [],
   "source": [
    "# define an iterator we will use to go over the dataset efficiently\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class DatasetBatchIterator:\n",
    "    \"Iterates over labaled dataset in batches\"\n",
    "    def __init__(self, X, Y, batch_size):\n",
    "        self.X = np.asarray(X)\n",
    "        self.Y = np.asarray(Y)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = int(math.ceil(X.shape[0] / batch_size))\n",
    "        self._current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.Y[k*bs:(k + 1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpjQEtyXcnq2",
    "outputId": "fd4cf33d-6d3e-4f6b-822f-212018fa57ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation progress: 100% (5550689/5550689)\n",
      "\n",
      "Popularity model RMSE: 0.9658\n"
     ]
    }
   ],
   "source": [
    "# evaluate the popularity model by iterating over the test dataset to compute predictions\n",
    "batch_size = 1024\n",
    "count = 0\n",
    "total = len(dataset_valid)\n",
    "groud_truth = np.empty([total])\n",
    "predictions = np.empty([total])\n",
    "\n",
    "X_val = dataset_valid[['userId','movieId']]\n",
    "Y_val = dataset_valid['rating']\n",
    "\n",
    "for x_batch, y_batch in DatasetBatchIterator(X_val, Y_val, batch_size):\n",
    "    actual_batch_size = len(x_batch)\n",
    "    y_hat_batch = np.empty([actual_batch_size])\n",
    "    for index, x in np.ndenumerate(x_batch[:,1]):\n",
    "        y_hat_batch[index] = popModel.predictRating(x)\n",
    "\n",
    "    groud_truth[count:count+actual_batch_size] = y_batch;\n",
    "    predictions[count:count+actual_batch_size] = y_hat_batch;\n",
    "    count += actual_batch_size\n",
    "    print(f'\\rEvaluation progress: {count/total*100:.0f}% ({count}/{total})', end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.9658\n",
      "Final MAPE: 0.3477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "RMSE = mean_squared_error(groud_truth, predictions, squared = False)\n",
    "MAPE = mean_absolute_percentage_error(groud_truth, predictions)\n",
    "\n",
    "# RMSE = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {RMSE:.4f}')\n",
    "print(f'Final MAPE: {MAPE:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
